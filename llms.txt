# Watty

> One memory. Every AI. It just knows you.

Watty is an MCP (Model Context Protocol) server that gives any AI persistent memory. It stores conversations, documents, and code locally in SQLite with semantic vector search. Works with Claude Desktop, Cursor, Windsurf, Claude Code, and any stdio MCP client.

## Core Concept

Watty runs as a local MCP server. When an AI platform queries Watty before responding, it gains natural awareness of the user's history — past conversations, scanned documents, stored preferences. The user types normally. The AI just knows things.

## Architecture

- **Storage:** SQLite database at `~/.watty/brain.db`
- **Embeddings:** `all-MiniLM-L6-v2` (384 dimensions) via onnxruntime or sentence-transformers
- **Search:** Cosine similarity with recency weighting
- **Chunking:** 1500 chars with 200 char overlap, smart boundary detection
- **Deduplication:** SHA-256 content hashing prevents duplicates

## 7 MCP Tools

- `watty_recall` — Search memory by meaning. Returns matches ranked by relevance with scores
- `watty_remember` — Save something to memory permanently
- `watty_scan` — Ingest files from a directory into memory
- `watty_forget` — Delete memories by query, ID, provider, or date
- `watty_surface` — Find unexpected connections in stored knowledge
- `watty_reflect` — Full brain overview: stats, providers, time range, knowledge clusters
- `watty_execute` — Run a command on the user's machine, get the output back as text

## Supported File Types

.txt .md .json .csv .log .py .js .ts .swift .rs .html .css .yaml .yml .toml .sh .bat .ps1

## Installation

```bash
git clone https://github.com/hugoboss23-5/WATTY.git
cd WATTY
pip install -e ".[onnx]"    # Recommended: ~100MB
# pip install -e ".[torch]" # Full: ~2GB, includes PyTorch
```

Add to Claude Desktop config (`~/.config/claude/claude_desktop_config.json` on Mac/Linux, `%APPDATA%\Claude\claude_desktop_config.json` on Windows):

```json
{
  "mcpServers": {
    "watty": {
      "command": "watty",
      "args": []
    }
  }
}
```

## Configuration (all optional)

- WATTY_HOME: ~/.watty/ (brain location)
- WATTY_EMBEDDING_MODEL: all-MiniLM-L6-v2
- WATTY_TOP_K: 10 (results per search)
- WATTY_RELEVANCE_THRESHOLD: 0.35
- WATTY_CHUNK_SIZE: 1500
- WATTY_CHUNK_OVERLAP: 200

## Links

- [README](https://github.com/hugoboss23-5/WATTY/blob/main/README.md)
- [Changelog](https://github.com/hugoboss23-5/WATTY/blob/main/CHANGELOG.md)
- [Security](https://github.com/hugoboss23-5/WATTY/blob/main/SECURITY.md)
- [Source: server.py](https://github.com/hugoboss23-5/WATTY/blob/main/watty/server.py)
- [Source: brain.py](https://github.com/hugoboss23-5/WATTY/blob/main/watty/brain.py)
- [Issues](https://github.com/hugoboss23-5/WATTY/issues)
- [License: MIT](https://github.com/hugoboss23-5/WATTY/blob/main/LICENSE)
